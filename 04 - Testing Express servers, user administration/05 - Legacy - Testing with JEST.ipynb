{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Legacy : Testing with Jest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **This is the old (pre 13th February 2024) content on testing that is using Jest as the testing library**. You may continue using this material if you have already started writing tests with Jest. In other case, you should ignore this page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Testing Node applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have completely neglected one essential area of software development, and that is automated testing.\n",
    "\n",
    "Let's start our testing journey by looking at unit tests. The logic of our application is so simple, that there is not much that makes sense to test with unit tests. Let's create a new file *utils/for_testing.js* and write a couple of simple functions that we can use for test writing practice:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```js\n",
    "const reverse = (string) => {\n",
    "  return string\n",
    "    .split('')\n",
    "    .reverse()\n",
    "    .join('')\n",
    "}\n",
    "\n",
    "const average = (array) => {\n",
    "  const reducer = (sum, item) => {\n",
    "    return sum + item\n",
    "  }\n",
    "\n",
    "  return array.reduce(reducer, 0) / array.length\n",
    "}\n",
    "\n",
    "module.exports = {\n",
    "  reverse,\n",
    "  average,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The `average` function uses the array [reduce](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Array/reduce) method. If the method is not familiar to you yet, then now is a good time to watch the first three videos from the [Functional Javascript](https://www.youtube.com/watch?v=BMUiFMZr7vk&list=PL0zVEGEvSaeEd9hlmCXrk5yUyqUag-n84) series on YouTube."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different testing libraries or *test runners* available for JavaScript. In this course we will be using a testing library developed and used internally by Facebook called [jest](https://jestjs.io/), which resembles the previous king of JavaScript testing libraries [Mocha](https://mochajs.org/).\n",
    "\n",
    "Jest is a natural choice for this course, as it works well for testing backends, and it shines when it comes to testing React applications.\n",
    "\n",
    "> **Windows users**: Jest may not work if the path of the project directory contains a directory that has spaces in its name.\n",
    "\n",
    "Since tests are only executed during the development of our application, we will install *jest* as a development dependency with the command:\n",
    "\n",
    "```cmd\n",
    "npm install --save-dev jest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the npm script `test` to execute tests with Jest and to report about the test execution with the *verbose* style:\n",
    "\n",
    "```json\n",
    "{\n",
    "  //...\n",
    "  \"scripts\": {\n",
    "    \"start\": \"node index.js\",\n",
    "    \"dev\": \"nodemon index.js\",\n",
    "    \"build:ui\": \"rm -rf build && cd ../frontend/ && npm run build && cp -r build ../backend\",\n",
    "    \"deploy\": \"fly deploy\",\n",
    "    \"deploy:full\": \"npm run build:ui && npm run deploy\",\n",
    "    \"logs:prod\": \"fly logs\",\n",
    "    \"lint\": \"eslint .\",\n",
    "    \"test\": \"jest --verbose\"\n",
    "  },\n",
    "  //...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jest requires one to specify that the execution environment is Node. This can be done by adding the following to the end of *package.json*:\n",
    "\n",
    "```json\n",
    "{\n",
    " //...\n",
    " \"jest\": {\n",
    "   \"testEnvironment\": \"node\"\n",
    " }\n",
    "}\n",
    "```\n",
    "\n",
    "Let's create a separate directory for our tests called tests and create a new file called *reverse.test.js* with the following contents:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```js\n",
    "const reverse = require('../utils/for_testing').reverse\n",
    "\n",
    "test('reverse of a', () => {\n",
    "  const result = reverse('a')\n",
    "\n",
    "  expect(result).toBe('a')\n",
    "})\n",
    "\n",
    "test('reverse of react', () => {\n",
    "  const result = reverse('react')\n",
    "\n",
    "  expect(result).toBe('tcaer')\n",
    "})\n",
    "\n",
    "test('reverse of releveler', () => {\n",
    "  const result = reverse('releveler')\n",
    "\n",
    "  expect(result).toBe('releveler')\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ESLint configuration we added to the project in the previous part complains about the `test` and `expect` commands in our test file since the configuration does not allow *globals*. Let's get rid of the complaints by adding *\"jest\"*: *true* to the *env* property in the *.eslintrc.js* file.\n",
    "\n",
    "```js\n",
    "module.exports = {\n",
    "  'env': {\n",
    "    'commonjs': true,\n",
    "    'es2021': true,\n",
    "    'node': true,\n",
    "    'jest': true,\n",
    "  },\n",
    "  // ...\n",
    "}\n",
    "```\n",
    "\n",
    "In the first row, the test file imports the function to be tested and assigns it to a variable called `reverse`:\n",
    "\n",
    "```js\n",
    "const reverse = require('../utils/for_testing').reverse\n",
    "```\n",
    "\n",
    "Individual test cases are defined with the `test` function. The first parameter of the function is the test description as a string. The second parameter is a *function*, that defines the functionality for the test case. The functionality for the second test case looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```js\n",
    "() => {\n",
    "  const result = reverse('react')\n",
    "\n",
    "  expect(result).toBe('tcaer')\n",
    "}\n",
    "```\n",
    "\n",
    "First, we execute the code to be tested, meaning that we generate a reverse for the string *react*. Next, we verify the results with the [expect](https://jestjs.io/docs/expect#expectvalue) function. Expect wraps the resulting value into an object that offers a collection of *matcher* functions, that can be used for verifying the correctness of the result. Since in this test case we are comparing two strings, we can use the [toBe](https://jestjs.io/docs/expect#tobevalue) matcher.\n",
    "\n",
    "As expected, all of the tests pass:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/image25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jest expects by default that the names of test files contain *.test*. In this course, we will follow the convention of naming our tests files with the extension *.test.js*.\n",
    "\n",
    "Jest has excellent error messages, let's break the test to demonstrate this:\n",
    "\n",
    "```js\n",
    "test('reverse of react', () => {\n",
    "  const result = reverse('react')\n",
    "\n",
    "  expect(result).toBe('tkaer')\n",
    "})\n",
    "```\n",
    "\n",
    "Running this test results in the following error message:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/image26.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add a few tests for the `average` function, into a new file *tests/average.test.js*.\n",
    "\n",
    "```js\n",
    "const average = require('../utils/for_testing').average\n",
    "\n",
    "describe('average', () => {\n",
    "  test('of one value is the value itself', () => {\n",
    "    expect(average([1])).toBe(1)\n",
    "  })\n",
    "\n",
    "  test('of many is calculated right', () => {\n",
    "    expect(average([1, 2, 3, 4, 5, 6])).toBe(3.5)\n",
    "  })\n",
    "\n",
    "  test('of empty array is zero', () => {\n",
    "    expect(average([])).toBe(0)\n",
    "  })\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test reveals that the function does not work correctly with an empty array (this is because in JavaScript dividing by zero results in *NaN*):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/image27.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixing the function is quite easy:\n",
    "\n",
    "```js\n",
    "const average = array => {\n",
    "  const reducer = (sum, item) => {\n",
    "    return sum + item\n",
    "  }\n",
    "\n",
    "  return array.length === 0\n",
    "    ? 0\n",
    "    : array.reduce(reducer, 0) / array.length\n",
    "}\n",
    "```\n",
    "\n",
    "If the length of the array is 0 then we return 0, and in all other cases, we use the `reduce` method to calculate the average.\n",
    "\n",
    "There are a few things to notice about the tests that we just wrote. We defined a *describe* block around the tests that were given the name `average`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```js\n",
    "describe('average', () => {\n",
    "  // tests\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Describe blocks can be used for grouping tests into logical collections. The test output of Jest also uses the name of the describe block:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/image28.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we will see later on *describe* blocks are necessary when we want to run some shared setup or teardown operations for a group of tests.\n",
    "\n",
    "Another thing to notice is that we wrote the tests in quite a compact way, without assigning the output of the function being tested to a variable:\n",
    "\n",
    "```js\n",
    "test('of empty array is zero', () => {\n",
    "  expect(average([])).toBe(0)\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Exercises 4.3.-4.7.\n",
    ">\n",
    "> Let's create a collection of helper functions that are meant to assist in dealing with the blog list. Create the functions into a file called *utils/list_helper.js*. Write your tests into an appropriately named test file under the *tests* directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 4.3: Helper Functions and Unit Tests, step 1\n",
    ">\n",
    "> First, define a `dummy` function that receives an array of blog posts as a parameter and always returns the value 1. The contents of the *list_helper.js* file at this point should be the following:\n",
    ">\n",
    "> ```js\n",
    "> const dummy = (blogs) => {\n",
    ">   // ...\n",
    "> }\n",
    ">\n",
    "> module.exports = {\n",
    ">   dummy\n",
    "> }\n",
    "> ```\n",
    ">\n",
    "> Verify that your test configuration works with the following test:\n",
    ">\n",
    "> ```js\n",
    "> const listHelper = require('../utils/list_helper')\n",
    ">\n",
    "> test('dummy returns one', () => {\n",
    ">   const blogs = []\n",
    "> \n",
    ">   const result = listHelper.dummy(blogs)\n",
    ">   expect(result).toBe(1)\n",
    "> })\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 4.4: Helper Functions and Unit Tests, step 2\n",
    ">\n",
    "> Define a new `totalLikes` function that receives a list of blog posts as a parameter. The function returns the total sum of *likes* in all of the blog posts.\n",
    ">\n",
    "> Write appropriate tests for the function. It's recommended to put the tests inside of a *describe* block so that the test report output gets grouped nicely:\n",
    ">\n",
    "> ![npm test passing for list_helper_test](./images/image29.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Defining test inputs for the function can be done like this:\n",
    ">\n",
    "> ```js\n",
    "> describe('total likes', () => {\n",
    ">   const listWithOneBlog = [\n",
    ">     {\n",
    ">       _id: '5a422aa71b54a676234d17f8',\n",
    ">       title: 'Go To Statement Considered Harmful',\n",
    ">       author: 'Edsger W. Dijkstra',\n",
    ">       url: 'https://homepages.cwi.nl/~storm/teaching/reader/Dijkstra68.pdf',\n",
    ">       likes: 5,\n",
    ">       __v: 0\n",
    ">     }\n",
    ">   ]\n",
    "> \n",
    ">   test('when list has only one blog, equals the likes of that', () => {\n",
    ">     const result = listHelper.totalLikes(listWithOneBlog)\n",
    ">     expect(result).toBe(5)\n",
    ">   })\n",
    "> })\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> If defining your own test input list of blogs is too much work, you can use the ready-made list [here](https://raw.githubusercontent.com/fullstack-hy2020/misc/master/blogs_for_test.md).\n",
    "> \n",
    "> You are bound to run into problems while writing tests. Remember the things that we learned about [debugging](https://fullstackopen.com/en/part3/saving_data_to_mongo_db#debugging-node-applications) in part 3. You can print things to the console with `console.log` even during test execution. It is even possible to use the debugger while running tests, you can find instructions for that [here](https://jestjs.io/docs/troubleshooting).\n",
    ">\n",
    "> **NB**: if some test is failing, then it is recommended to only run that test while you are fixing the issue. You can run a single test with the [only](https://jestjs.io/docs/api#testonlyname-fn-timeout) method.\n",
    ">\n",
    "> Another way of running a single test (or describe block) is to specify the name of the test to be run with the [-t](https://jestjs.io/docs/cli) flag:\n",
    ">\n",
    "> ```cmd\n",
    "> npm test -- -t 'when list has only one blog, equals the likes of that'\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 4.5*: Helper Functions and Unit Tests, step 3\n",
    ">\n",
    "> Define a new `favoriteBlog` function that receives a list of blogs as a parameter. The function finds out which blog has the most likes. If there are many top favorites, it is enough to return one of them.\n",
    ">\n",
    "> The value returned by the function could be in the following format:\n",
    ">\n",
    "> ```js\n",
    "> {\n",
    ">   title: \"Canonical string reduction\",\n",
    ">   author: \"Edsger W. Dijkstra\",\n",
    ">   likes: 12\n",
    "> }\n",
    "> ```\n",
    ">\n",
    "> **NB** when you are comparing objects, the [toEqual](https://jestjs.io/docs/expect#toequalvalue) method is probably what you want to use, since the [toBe](https://jestjs.io/docs/expect#tobevalue) tries to verify that the two values are the same value, and not just that they contain the same properties.\n",
    ">\n",
    "> Write the tests for this exercise inside of a new *describe* block. Do the same for the remaining exercises as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 4.6*: Helper Functions and Unit Tests, step 4\n",
    "> \n",
    "> This and the next exercise are a little bit more challenging. Finishing these two exercises is not required to advance in the course material, so it may be a good idea to return to these once you're done going through the material for this part in its entirety.\n",
    ">\n",
    "> Finishing this exercise can be done without the use of additional libraries. However, this exercise is a great opportunity to learn how to use the [Lodash](https://lodash.com/) library.\n",
    ">\n",
    "> Define a function called `mostBlogs` that receives an array of blogs as a parameter. The function returns the *author* who has the largest amount of blogs. The return value also contains the number of blogs the top author has:\n",
    "> \n",
    "> ```js\n",
    "> {\n",
    ">   author: \"Robert C. Martin\",\n",
    ">   blogs: 3\n",
    "> }\n",
    "> ```\n",
    ">\n",
    "> If there are many top bloggers, then it is enough to return any one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 4.7*: Helper Functions and Unit Tests, step 5\n",
    ">\n",
    "> Define a function called `mostLikes` that receives an array of blogs as its parameter. The function returns the author, whose blog posts have the largest amount of likes. The return value also contains the total number of likes that the author has received:\n",
    ">\n",
    "> {\n",
    ">   author: \"Edsger W. Dijkstra\",\n",
    ">   likes: 17\n",
    "> }\n",
    "> ```\n",
    "> \n",
    "> If there are many top bloggers, then it is enough to show any one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now start writing tests for the backend. Since the backend does not contain any complicated logic, it doesn't make sense to write [unit tests](https://en.wikipedia.org/wiki/Unit_testing) for it. The only potential thing we could unit test is the `toJSON` method that is used for formatting notes.\n",
    "\n",
    "In some situations, it can be beneficial to implement some of the backend tests by mocking the database instead of using a real database. One library that could be used for this is [mongodb-memory-server](https://github.com/typegoose/mongodb-memory-server).\n",
    "\n",
    "Since our application's backend is still relatively simple, we will decide to test the entire application through its REST API, so that the database is also included. This kind of testing where multiple components of the system are being tested as a group is called [integration testing](https://en.wikipedia.org/wiki/Integration_testing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Test environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one of the previous chapters of the course material, we mentioned that when your backend server is running in Fly.io or Render, it is in *production* mode.\n",
    "\n",
    "The convention in Node is to define the execution mode of the application with the *NODE_ENV* environment variable. In our current application, we only load the environment variables defined in the *.env* file if the application is *not* in production mode.\n",
    "\n",
    "It is common practice to define separate modes for development and testing.\n",
    "\n",
    "Next, let's change the scripts in our notes application *package.json* file, so that when tests are run, *NODE_ENV* gets the value *test*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```js\n",
    "{\n",
    "  // ...\n",
    "  \"scripts\": {\n",
    "\n",
    "    \"start\": \"NODE_ENV=production node index.js\",\n",
    "    \"dev\": \"NODE_ENV=development nodemon index.js\",\n",
    "    \"build:ui\": \"rm -rf build && cd ../frontend/ && npm run build && cp -r build ../backend\",\n",
    "    \"deploy\": \"fly deploy\",\n",
    "    \"deploy:full\": \"npm run build:ui && npm run deploy\",\n",
    "    \"logs:prod\": \"fly logs\",\n",
    "    \"lint\": \"eslint .\",\n",
    "\n",
    "    \"test\": \"NODE_ENV=test jest --verbose --runInBand\"\n",
    "  },\n",
    "  // ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also added the [runInBand](https://jestjs.io/docs/cli#--runinband) option to the npm script that executes the tests. This option will prevent Jest from running tests in parallel; we will discuss its significance once our tests start using the database.\n",
    "\n",
    "We specified the mode of the application to be *development* in the `npm run dev` script that uses nodemon. We also specified that the default `npm start` command will define the mode as production.\n",
    "\n",
    "There is a slight issue in the way that we have specified the mode of the application in our scripts: it will not work on Windows. We can correct this by installing the [cross-env](https://www.npmjs.com/package/cross-env) package as a development dependency with the command:\n",
    "\n",
    "```cmd\n",
    "npm install --save-dev cross-env\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then achieve cross-platform compatibility by using the cross-env library in our npm scripts defined in *package.json*:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "  // ...\n",
    "  \"scripts\": {\n",
    "    \"start\": \"cross-env NODE_ENV=production node index.js\",\n",
    "    \"dev\": \"cross-env NODE_ENV=development nodemon index.js\",\n",
    "    // ...\n",
    "    \"test\": \"cross-env NODE_ENV=test jest --verbose --runInBand\",\n",
    "  },\n",
    "  // ...\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB**: If you are deploying this application to Fly.io/Render, keep in mind that if cross-env is saved as a development dependency, it would cause an application error on your web server. To fix this, change cross-env to a production dependency by running this in the command line:\n",
    "\n",
    "```cmd\n",
    "npm install cross-env\n",
    "```\n",
    "\n",
    "Now we can modify the way that our application runs in different modes. As an example of this, we could define the application to use a separate test database when it is running tests.\n",
    "\n",
    "We can create our separate test database in MongoDB Atlas. This is not an optimal solution in situations where many people are developing the same application. Test execution in particular typically requires a single database instance that is not used by tests that are running concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be better to run our tests using a database that is installed and running on the developer's local machine. The optimal solution would be to have every test execution use a separate database. This is \"relatively simple\" to achieve by [running Mongo in-memory](https://www.mongodb.com/docs/manual/core/inmemory/) or by using [Docker](https://www.docker.com/) containers. We will not complicate things and will instead continue to use the MongoDB Atlas database.\n",
    "\n",
    "Let's make some changes to the module that defines the application's configuration in `utils/config.js`:\n",
    "\n",
    "```js\n",
    "require('dotenv').config()\n",
    "\n",
    "const PORT = process.env.PORT\n",
    "\n",
    "const MONGODB_URI = process.env.NODE_ENV === 'test' \n",
    "  ? process.env.TEST_MONGODB_URI\n",
    "  : process.env.MONGODB_URI\n",
    "\n",
    "module.exports = {\n",
    "  MONGODB_URI,\n",
    "  PORT\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *.env* file has *separate variables* for the database addresses of the development and test databases:\n",
    "\n",
    "```cmd\n",
    "MONGODB_URI=mongodb+srv://fullstack:thepasswordishere@cluster0.o1opl.mongodb.net/noteApp?retryWrites=true&w=majority\n",
    "PORT=3001\n",
    "\n",
    "TEST_MONGODB_URI=mongodb+srv://fullstack:thepasswordishere@cluster0.o1opl.mongodb.net/testNoteApp?retryWrites=true&w=majority\n",
    "```\n",
    "\n",
    "The `config` module that we have implemented slightly resembles the [node-config](https://github.com/node-config/node-config) package. Writing our implementation is justified since our application is simple, and also because it teaches us valuable lessons.\n",
    "\n",
    "These are the only changes we need to make to our application's code.\n",
    "\n",
    "You can find the code for our current application in its entirety in the *part4-2* branch of [this GitHub repository](https://github.com/fullstack-hy2020/part3-notes-backend/tree/part4-2)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## supertest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the [supertest]() package to help us write our tests for testing the API.\n",
    "\n",
    "We will install the package as a development dependency:\n",
    "\n",
    "```cmd\n",
    "npm install --save-dev supertest\n",
    "```\n",
    "\n",
    "Let's write our first test in the *tests/note_api.test.js* file:\n",
    "\n",
    "```js\n",
    "const mongoose = require('mongoose')\n",
    "const supertest = require('supertest')\n",
    "const app = require('../app')\n",
    "\n",
    "const api = supertest(app)\n",
    "\n",
    "test('notes are returned as json', async () => {\n",
    "  await api\n",
    "    .get('/api/notes')\n",
    "    .expect(200)\n",
    "    .expect('Content-Type', /application\\/json/)\n",
    "})\n",
    "\n",
    "afterAll(async () => {\n",
    "  await mongoose.connection.close()\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test imports the Express application from the *app.js* module and wraps it with the *supertest* function into a so-called [superagent](https://github.com/ladjs/superagent) object. This object is assigned to the *api* variable and tests can use it for making HTTP requests to the backend.\n",
    "\n",
    "Our test makes an HTTP GET request to the *api/notes* url and verifies that the request is responded to with the status code 200. The test also verifies that the Content-Type header is set to application/json, indicating that the data is in the desired format.\n",
    "\n",
    "Checking the value of the header uses a bit strange looking syntax:\n",
    "\n",
    "```json\n",
    ".expect('Content-Type', /application\\/json/)\n",
    "```\n",
    "\n",
    "The desired value is now defined as [regular expression](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Regular_expressions) or in short regex. The regex starts and ends with a slash /, because the desired string *application/json* also contains the same slash, it is preceded by a \\ so that it is not interpreted as a regex termination character.\n",
    "\n",
    "In principle, the test could also have been defined as a string\n",
    "\n",
    "```js\n",
    ".expect('Content-Type', 'application/json')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem here, however, is that when using a string, the value of the header must be exactly the same. For the regex we defined, it is acceptable that the header *contains* the string in question. The actual value of the header is *application/json; charset=utf-8,* i.e. it also contains information about character encoding. However, our test is not interested in this and therefore it is better to define the test as a regex instead of an exact string.\n",
    "\n",
    "The test contains some details that we will explore [a bit later on](https://fullstackopen.com/en/part4/testing_the_backend#async-await). The arrow function that defines the test is preceded by the async keyword and the method call for the api object is preceded by the await keyword. We will write a few tests and then take a closer look at this async/await magic. Do not concern yourself with them for now, just be assured that the example tests work correctly. The async/await syntax is related to the fact that making a request to the API is an *asynchronous* operation. The [async/await syntax](https://jestjs.io/docs/asynchronous) can be used for writing asynchronous code with the appearance of synchronous code.\n",
    "\n",
    "Once all the tests (there is currently only one) have finished running we have to close the database connection used by Mongoose. This can be easily achieved with the [afterAll](https://jestjs.io/docs/api#afterallfn-timeout) method:\n",
    "\n",
    "```js\n",
    "afterAll(async () => {\n",
    "  await mongoose.connection.close()\n",
    "})\n",
    "```\n",
    "\n",
    "When running your tests you may run across the following console warning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/image30.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is quite likely caused by the Mongoose version 6.x, the problem does not appear when version 5.x or 7.x is used. [Mongoose documentation](https://mongoosejs.com/docs/jest.html) does not recommend testing Mongoose applications with Jest.\n",
    "\n",
    "[One way](https://stackoverflow.com/questions/50687592/jest-and-mongoose-jest-has-detected-opened-handles) to get rid of this is to add to the directory tests a file *teardown.js* with the following content\n",
    "\n",
    "```js\n",
    "module.exports = () => {\n",
    "  process.exit(0)\n",
    "}\n",
    "```\n",
    "\n",
    "and by extending the Jest definitions in the *package.json* as follows\n",
    "\n",
    "```json\n",
    "{\n",
    " //...\n",
    " \"jest\": {\n",
    "   \"testEnvironment\": \"node\",\n",
    "   \"globalTeardown\": \"./tests/teardown.js\"\n",
    " }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another error you may come across is your test takes longer than the default Jest test timeout of 5000 ms. This can be solved by adding a third parameter to the test function:\n",
    "\n",
    "```js\n",
    "test('notes are returned as json', async () => {\n",
    "  await api\n",
    "    .get('/api/notes')\n",
    "    .expect(200)\n",
    "    .expect('Content-Type', /application\\/json/)\n",
    "}, 100000)\n",
    "```\n",
    "\n",
    "This third parameter sets the timeout to 100000 ms. A long timeout ensures that our test won't fail due to the time it takes to run. (A long timeout may not be what you want for tests based on performance or speed, but this is fine for our example tests).\n",
    "\n",
    "If you still encounter issues with mongoose timeouts, set `bufferTimeoutMS` variable to a value significantly higher than 10000 (10 seconds). You could set it like this at the top, right after the `require` statements. `mongoose.set(\"bufferTimeoutMS\", 30000)`\n",
    "\n",
    "One tiny but important detail: at the [beginning](https://fullstackopen.com/en/part4/structure_of_backend_application_introduction_to_testing#project-structure) of this part we extracted the Express application into the *app.js* file, and the role of the *index.js* file was changed to launch the application at the specified port via `app.listen`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```js\n",
    "const app = require('./app') // the actual Express app\n",
    "const config = require('./utils/config')\n",
    "const logger = require('./utils/logger')\n",
    "\n",
    "app.listen(config.PORT, () => {\n",
    "  logger.info(`Server running on port ${config.PORT}`)\n",
    "})\n",
    "```\n",
    "\n",
    "The tests only use the Express application defined in the *app.js* file, which does not listen to any ports:\n",
    "\n",
    "```js\n",
    "const mongoose = require('mongoose')\n",
    "const supertest = require('supertest')\n",
    "const app = require('../app')\n",
    "\n",
    "const api = supertest(app)\n",
    "\n",
    "// ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation for supertest says the following:\n",
    "\n",
    "> if the server is not already listening for connections then it is bound to an ephemeral port for you so there is no need to keep track of ports.\n",
    "\n",
    "In other words, supertest takes care that the application being tested is started at the port that it uses internally.\n",
    "\n",
    "Let's add two notes to the test database using the `mongo.js` program (here we must remember to switch to the correct database url).\n",
    "\n",
    "Let's write a few more tests:\n",
    "\n",
    "```js\n",
    "test('there are two notes', async () => {\n",
    "  const response = await api.get('/api/notes')\n",
    "\n",
    "  expect(response.body).toHaveLength(2)\n",
    "})\n",
    "\n",
    "test('the first note is about HTTP methods', async () => {\n",
    "  const response = await api.get('/api/notes')\n",
    "\n",
    "  expect(response.body[0].content).toBe('HTML is easy')\n",
    "})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both tests store the response of the request to the `response` variable, and unlike the previous test that used the methods provided by `supertest` for verifying the status code and headers, this time we are inspecting the response data stored in *response.body* property. Our tests verify the format and content of the response data with the [expect](https://jestjs.io/docs/expect#expectvalue) method of Jest.\n",
    "\n",
    "The benefit of using the async/await syntax is starting to become evident. Normally we would have to use callback functions to access the data returned by promises, but with the new syntax things are a lot more comfortable:\n",
    "\n",
    "```js\n",
    "const response = await api.get('/api/notes')\n",
    "\n",
    "// execution gets here only after the HTTP request is complete\n",
    "// the result of HTTP request is saved in variable response\n",
    "expect(response.body).toHaveLength(2)\n",
    "```\n",
    "\n",
    "The middleware that outputs information about the HTTP requests is obstructing the test execution output. Let us modify the logger so that it does not print to the console in test mode:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```js\n",
    "const info = (...params) => {\n",
    "\n",
    "  if (process.env.NODE_ENV !== 'test') { \n",
    "    console.log(...params)\n",
    "  }\n",
    "}\n",
    "\n",
    "const error = (...params) => {\n",
    "\n",
    "  if (process.env.NODE_ENV !== 'test') { \n",
    "    console.error(...params)\n",
    "  }\n",
    "}\n",
    "\n",
    "module.exports = {\n",
    "  info, error\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Initializing the database before tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
